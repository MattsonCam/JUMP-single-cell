{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "7T0gePh3Zn"
      },
      "source": [
        "# Download sqlite plate data from aws\n",
        "Note, this script was not rerun to display the outputs for the sake of time. To download the data, you must be signed into your aws account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ddhh5egm7R"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "XqllLfeEBZ"
      },
      "source": [
        "import pathlib\n",
        "import subprocess"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "q52bES5PJV"
      },
      "source": [
        "## Find the root of the git directory\n",
        "This allows file paths to be referenced in a system agnostic way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xCbL8BuHjD"
      },
      "source": [
        "# Get the current working directory\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "if (cwd / \".git\").is_dir():\n",
        "    root_dir = cwd\n",
        "\n",
        "else:\n",
        "    root_dir = None\n",
        "    for parent in cwd.parents:\n",
        "        if (parent / \".git\").is_dir():\n",
        "            root_dir = parent\n",
        "            break\n",
        "\n",
        "# Check if a Git root directory was found\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"No Git root directory found.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "DgPm3tAEsr"
      },
      "source": [
        "## Download the plate sqlite data from AWS S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "NDX1gPfGsN"
      },
      "source": [
        "# Specify the data path for downloading the data\n",
        "download_map = \"data/jump_dataset_location_manifest.csv\"\n",
        "\n",
        "# Specify the location to save the data\n",
        "save_location = f\"{root_dir}/big_drive/sc_data\"\n",
        "\n",
        "# The script for downloading sqlite files from aws\n",
        "aws_download_script = \"download_from_aws.sh\"\n",
        "\n",
        "# The column name of the sqlite file\n",
        "path_column = \"sqlite_file\"\n",
        "\n",
        "# Create the necessary directories if non-existent\n",
        "pathlib.Path(save_location).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the data using a bash script\n",
        "subprocess.run([\"bash\", aws_download_script, download_map, save_location, path_column])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "CompletedProcess(args=['bash', 'download_from_aws.sh', 'data/jump_dataset_location_manifest.csv', '/home/camo/projects/JUMP-single-cell/big_drive/data', 'sqlite_file'], returncode=0)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}