{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "M0WvWCZ1Aa"
      },
      "source": [
        "# Preprocess using pyctyominer and merge broad samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "cDsoC3Gcm4"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "DgPm3tAEsr"
      },
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pycytominer import normalize\n",
        "from pycytominer.cyto_utils.cells import SingleCells"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "NPDmhE8H6X"
      },
      "source": [
        "## Find the root of the git directory\n",
        "This allows file paths to be referenced in a system agnostic way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "yZSVxXoYEz"
      },
      "source": [
        "# Get the current working directory\n",
        "cwd = Path.cwd()\n",
        "\n",
        "if (cwd / \".git\").is_dir():\n",
        "    root_dir = cwd\n",
        "\n",
        "else:\n",
        "    root_dir = None\n",
        "    for parent in cwd.parents:\n",
        "        if (parent / \".git\").is_dir():\n",
        "            root_dir = parent\n",
        "            break\n",
        "\n",
        "# Check if a Git root directory was found\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"No Git root directory found.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "EAFlLWTJ8h"
      },
      "source": [
        "## Define Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "OZedqnuQgs"
      },
      "source": [
        "# Input paths\n",
        "big_drive_path = f\"{root_dir}/big_drive\"\n",
        "sqlite_data_path = f\"{big_drive_path}/data\"\n",
        "ref_path = f\"{root_dir}/1.process_data/reference_plate_data\"\n",
        "barcode_platemap = f\"{ref_path}/barcode_platemap.csv\"\n",
        "\n",
        "# Output paths\n",
        "output_cell_count_path = Path(f\"{big_drive_path}/sc_counts\")\n",
        "normalized_path = Path(f\"{big_drive_path}/normalized_sc_data\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "uGOqoaUkaq"
      },
      "source": [
        "## Create directories if non-existent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RrixMBTKVc"
      },
      "source": [
        "output_cell_count_path.mkdir(parents=True, exist_ok=True)\n",
        "normalized_path.mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "b6AFJS78yk"
      },
      "source": [
        "# Create dataframe from barcode platemap\n",
        "barcode_df = pd.read_csv(barcode_platemap)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "zNtqXlqkiR"
      },
      "source": [
        "# Process cell data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "5SOBQxOXXE"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "891gvwyvIr"
      },
      "source": [
        "# Add the 'Metadata' prefix to column names\n",
        "def add_metadata_prefix_to_column_names(df):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    df: pandas Dataframe\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df: pandas Dataframe\n",
        "        A dataframe with the column names prefixed with the string 'Metadata'\n",
        "    \"\"\"\n",
        "\n",
        "    df.rename(columns=lambda x: f\"Metadata_{x}\", inplace=True)\n",
        "    return df\n",
        "\n",
        "# Fill in broad_sample \"DMSO\" for NaN and prefix the column names\n",
        "def fill_dmso(df):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    df: pandas Dataframe\n",
        "        A dataframe of the platemap data and a corresponding 'broad_sample' column\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df: pandas Dataframe\n",
        "    A dataframe with without empty broad_samples and renamed columns\n",
        "    \"\"\"\n",
        "\n",
        "    df[\"broad_sample\"] = df[\"broad_sample\"].fillna(\"DMSO\")\n",
        "    df = add_metadata_prefix_to_column_names(df)\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "r5VX7kI86O"
      },
      "source": [
        "## Map reference data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xlSyhljTz3"
      },
      "source": [
        "# Merge on the broad_sample column\n",
        "merge_col = \"Metadata_broad_sample\"\n",
        "\n",
        "compdf = pd.read_csv(f\"{ref_path}/JUMP-Target-1_compound_metadata_targets.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Set empty broad samples to DMSO if the pert iname is DMSO for the compounds dataframe\n",
        "compdf.loc[compdf[\"pert_iname\"] == \"DMSO\", \"broad_sample\"] = \"DMSO\"\n",
        "\n",
        "# Map platemap names found in the barcode file to metadata dataframes\n",
        "barcode_map = {\"JUMP-Target-1_orf_platemap\": pd.read_csv(f\"{ref_path}/JUMP-Target-1_orf_metadata.tsv\", sep=\"\\t\"),\n",
        "               \"JUMP-Target-1_crispr_platemap\": pd.read_csv(f\"{ref_path}/JUMP-Target-1_crispr_metadata.tsv\", sep=\"\\t\"),\n",
        "                \"JUMP-Target-1_compound_platemap\": compdf}\n",
        "\n",
        "# Map platemap names found in the barcode file to platemap dataframes\n",
        "platemeta2df = {platemap_name: pd.read_csv(f\"{ref_path}/{platemap_name}.txt\", sep=\"\\t\") for platemap_name, _ in barcode_map.items()}\n",
        "\n",
        "# Map the wells corresponding to the empty broad samples in the plate metadata files\n",
        "platemeta2cols = {name: df.loc[df[\"broad_sample\"].isnull()][\"well_position\"].tolist() for name, df in platemeta2df.items() if name != \"JUMP-Target-1_compound_platemap\"}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "XGivCKnP82"
      },
      "source": [
        "## Rename columns and fill control values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "XtCuBmuSwW"
      },
      "source": [
        "# Rename colunns in plate metadata\n",
        "barcode_map = {df_name: add_metadata_prefix_to_column_names(df) for df_name, df in barcode_map.items()}\n",
        "\n",
        "# Fill the broad_sample missing values with DMSO for the plate metadata\n",
        "platemeta2df = {df_name: fill_dmso(df) for df_name, df in platemeta2df.items()}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "hNC232BAxW"
      },
      "source": [
        "## Merge and Normalize plate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "B4ITtH72EK"
      },
      "source": [
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Iterate through each plate in the barcode dataframe\n",
        "for idx, row in barcode_df.iterrows():\n",
        "\n",
        "    # Get the plate name\n",
        "    plate_name = row[\"Assay_Plate_Barcode\"]\n",
        "\n",
        "    # Get the platemap name\n",
        "    plate_map = row[\"Plate_Map_Name\"]\n",
        "\n",
        "    # Get the plate metadata dataframe from the platemap name\n",
        "    broad_mapdf = barcode_map[plate_map]\n",
        "\n",
        "    # Final path of each cell count output file\n",
        "    output_cell_count_file = f\"{output_cell_count_path}/{plate_name}_cellcount.tsv\"\n",
        "\n",
        "    # Path of each normalized out single cell dataset\n",
        "    output_file = f\"{normalized_path}/{plate_name}_normalized_sc.parquet\"\n",
        "\n",
        "    # Path of the original sqlite file\n",
        "    sqlite_file = f\"sqlite:///{sqlite_data_path}/{plate_name}.sqlite\"\n",
        "\n",
        "    # Create dataframe from plate metadata\n",
        "    platemeta_df = platemeta2df[plate_map]\n",
        "\n",
        "    # Get the single cell data\n",
        "    sc = SingleCells(sql_file=sqlite_file, default_datatype_float=np.float32)\n",
        "\n",
        "    # Output the cell count data\n",
        "    cell_count_df = sc.count_cells()\n",
        "    cell_count_df.to_csv(output_cell_count_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    # Merge single cells\n",
        "    sc_df = sc.merge_single_cells(platemap=platemeta_df)\n",
        "\n",
        "    # Merge the dataframes based on the broad_sample column\n",
        "    sc_df = pd.merge(sc_df, broad_mapdf, how=\"left\", on=merge_col)\n",
        "\n",
        "    # We only change the columns if the plate does not contain empty wells\n",
        "    if plate_map != \"JUMP-Target-1_compound_platemap\":\n",
        "        sc_df.loc[sc_df[\"Metadata_Well\"].isin(platemeta2cols[plate_map]), broad_mapdf.columns] = \"no_treatment\"\n",
        "\n",
        "    # Normalize the data\n",
        "    normalize(\n",
        "        profiles=sc_df,\n",
        "        features=\"infer\",\n",
        "        image_features=False,\n",
        "        meta_features=\"infer\",\n",
        "        samples=\"Metadata_control_type == 'negcon'\",\n",
        "        method=\"standardize\",\n",
        "        output_file=output_file,\n",
        "        output_type=\"parquet\",\n",
        "    )\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[0;31m---------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                           Traceback (most recent call last)\nCell \u001b[0;32mIn[17], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m         sc_df\u001b[38;5;241m.\u001b[39mloc[sc_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata_Well\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(platemeta2cols[plate_map]), broad_mapdf\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_treatment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Normalize the data\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msc_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMetadata_control_type == \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegcon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandardize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     58\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\n\u001b[0;31mTypeError\u001b[0m: normalize() got an unexpected keyword argument 'output_type'\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "FwAgRkxcQ6"
      },
      "source": [
        "## Specify the time taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "H6A3v3ORWD"
      },
      "source": [
        "t_minutes = (end_time - start_time) // 60\n",
        "t_hours = t_minutes / 60\n",
        "print(f\"Total time taken = {t_minutes} minutes\")\n",
        "print(f\"Total time taken = {t_hours} hours\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[0;31m---------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)\nCell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_minutes \u001b[38;5;241m=\u001b[39m (\u001b[43mend_time\u001b[49m \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m      2\u001b[0m t_hours \u001b[38;5;241m=\u001b[39m t_minutes \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time taken = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_minutes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'end_time' is not defined\n"
        }
      ],
      "execution_count": 2
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}