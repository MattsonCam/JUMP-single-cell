{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "M0WvWCZ1Aa"
      },
      "source": [
        "# Preprocess using pyctyominer and merge broad samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "cDsoC3Gcm4"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "DgPm3tAEsr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "from pathlib import Path\n",
        "from pycytominer.cyto_utils.cells import SingleCells\n",
        "from pycytominer import normalize\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "EAFlLWTJ8h"
      },
      "source": [
        "## Define Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "OZedqnuQgs"
      },
      "source": [
        "# Get the home directory\n",
        "home_directory = os.environ[\"HOME\"]\n",
        "\n",
        "# Input paths\n",
        "barcode_platemap = \"barcode_platemap.csv\"\n",
        "broad_map = \"repurposing_info_external_moa_map_resolved.tsv\"\n",
        "big_drive_path = f\"{home_directory}/projects/phenotypic_profiling_analysis/jump_test_dataset/big_drive\"\n",
        "sqlite_data_path = f\"{big_drive_path}/data\"\n",
        "\n",
        "# Output paths\n",
        "output_cell_count_path = Path(f\"{big_drive_path}/sc_counts\")\n",
        "normalized_path = Path(f\"{big_drive_path}/normalized_sc_data\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "uGOqoaUkaq"
      },
      "source": [
        "## Create directories if non-existent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RrixMBTKVc"
      },
      "source": [
        "output_cell_count_path.mkdir(parents=True, exist_ok=True)\n",
        "normalized_path.mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "b6AFJS78yk"
      },
      "source": [
        "# Create dataframe from barcode platemap\n",
        "barcode_df = pd.read_csv(barcode_platemap)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "zNtqXlqkiR"
      },
      "source": [
        "# Process cell data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "r5VX7kI86O"
      },
      "source": [
        "## Rename broad columns for mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xlSyhljTz3"
      },
      "source": [
        "# Merge on the broad_sample column\n",
        "merge_col = \"Metadata_broad_sample\"\n",
        "\n",
        "broad_mapdf = pd.read_csv(broad_map, sep=\"\\t\")\n",
        "broad_mapdf = broad_mapdf.rename(columns={\"broad_sample\": merge_col})\n",
        "broad_mapdf = broad_mapdf[[merge_col, \"moa\", \"pert_iname\"]]\n",
        "broad_mapdf = broad_mapdf.rename(\n",
        "    columns={\"moa\": \"Metadata_moa\", \"pert_iname\": \"Metadata_pert_iname\"}\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "B4ITtH72EK"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for idx, row in barcode_df.iterrows():\n",
        "\n",
        "    # Get the plate map name from the barcode\n",
        "    # plate_map_name = barcode_df.loc[barcode_df['Assay_Plate_Barcode'] == row['plate']]['Plate_Map_Name']\n",
        "    plate_name = row[\"Assay_Plate_Barcode\"]\n",
        "    plate_map = row[\"Plate_Map_Name\"]\n",
        "\n",
        "    # Get the plate name\n",
        "    output_cell_count_file = f\"{output_cell_count_path}/{plate_name}_cellcount.tsv\"\n",
        "    output_file = f\"{normalized_path}/{plate_name}_normalized_sc.parquet\"\n",
        "    sqlite_file = f\"sqlite:///{sqlite_data_path}/{plate_name}.sqlite\"\n",
        "\n",
        "    # Specify the platemap file\n",
        "    platemap_df = pd.read_csv(f\"{plate_map}.txt\", sep=\"\\t\")\n",
        "\n",
        "    # Fill in broad_sample \"DMSO\" for NaN\n",
        "    platemap_df.broad_sample = platemap_df.broad_sample.fillna(\"DMSO\")\n",
        "    platemap_df.columns = [f\"Metadata_{x}\" for x in platemap_df.columns]\n",
        "\n",
        "    # Get the single cell data\n",
        "    sc = SingleCells(sql_file=sqlite_file, default_datatype_float=np.float32)\n",
        "\n",
        "    # Output the single cell data\n",
        "    cell_count_df = sc.count_cells()\n",
        "    cell_count_df.to_csv(output_cell_count_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    # Merge single cells\n",
        "    sc_df = sc.merge_single_cells(platemap=platemap_df)\n",
        "\n",
        "    # Merge the dataframes based on the broad_sample column\n",
        "    sc_df = pd.merge(sc_df, broad_mapdf, how=\"left\", on=merge_col)\n",
        "\n",
        "    # Normalize the data\n",
        "    normalize(\n",
        "        profiles=sc_df,\n",
        "        features=\"infer\",\n",
        "        image_features=False,\n",
        "        meta_features=\"infer\",\n",
        "        samples=\"Metadata_broad_sample == 'DMSO'\",\n",
        "        method=\"standardize\",\n",
        "        output_file=output_file,\n",
        "        output_type=\"parquet\",\n",
        "    )\n",
        "\n",
        "end_time = time.time()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[0;31m-------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)\nCell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbarcode_df\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Get the plate map name from the barcode\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#plate_map_name = barcode_df.loc[barcode_df['Assay_Plate_Barcode'] == row['plate']]['Plate_Map_Name']\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     plate_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssay_Plate_Barcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m     plate_map \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlate_Map_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\n\u001b[0;31mNameError\u001b[0m: name 'barcode_df' is not defined\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "H6A3v3ORWD"
      },
      "source": [
        "t_minutes = (end_time - start_time) // 60\n",
        "t_hours = t_minutes / 60\n",
        "print(f\"Total time taken = {t_minutes} minutes\")\n",
        "print(f\"Total time taken = {t_hours} hours\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[0;31m-------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)\nCell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_minutes \u001b[38;5;241m=\u001b[39m (\u001b[43mend_time\u001b[49m \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\n\u001b[1;32m      2\u001b[0m t_hours \u001b[38;5;241m=\u001b[39m t_minutes \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time taken = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_minutes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'end_time' is not defined\n"
        }
      ],
      "execution_count": 2
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}